{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import codecs\n",
    "import re\n",
    "import string\n",
    "import io\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Articles from:\n",
    "    https://sites.google.com/site/qianmingjie/home/datasets/cnn-and-fox-news\n",
    "    \n",
    "@inproceedings{qian2014unsupervised,\n",
    "  title={Unsupervised Feature Selection for Multi-View Clustering on Text-Image Web News Data},\n",
    "  author={Qian, Mingjie and Zhai, Chengxiang},\n",
    "  booktitle={Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management},\n",
    "  pages={1963--1966},\n",
    "  year={2014},\n",
    "  organization={ACM}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/7of9/Documents/Word2Vec/')\n",
    "f = open('FOX/DocList.txt', 'r')\n",
    "fox_list = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/7of9/Documents/Word2Vec/FOX'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('FOX/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "fox_files = []\n",
    "for file in fox_list:\n",
    "    file = file.split(\"\\\\\")[0] + \"/\" + file.split(\"\\\\\")[1]\n",
    "    file = file.replace(\"\\n\", \"\")\n",
    "    fox_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foxnews_health/foxnews_health-00002045-20140101060012CST.txt',\n",
       " 'foxnews_health/foxnews_health-00002046-20140101053044CST.txt',\n",
       " 'foxnews_health/foxnews_health-00002047-20140101053001CST.txt']"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fox_files[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(text):\n",
    "    regex = re.compile('[' + 'â€“' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')   \n",
    "    text = regex.sub(\" \", text)\n",
    "    words = text.split()\n",
    "    wordsL = [word.lower() for word in words]\n",
    "    return(wordsL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7691514/extracting-text-from-xml-using-python\n",
    "from xml.etree import cElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "os.chdir('Raw/')\n",
    "fox_docs = []\n",
    "for text in fox_files[20:]:\n",
    "    with open(text) as f:\n",
    "        soup = BeautifulSoup(f, 'xml')\n",
    "    content = soup.find_all('TEXT')\n",
    "    fox_docs.append(words(str(content).replace('TEXT', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shoveling', 'snow', 'can', 'take', 'a', 'toll', 'on', 'your', 'body']"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fox_docs[0][0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "fox_model = Word2Vec(fox_docs, min_count=1, size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=33743, size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(fox_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(fox_model.wv.vocab)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/7of9/Documents/Word2Vec/')\n",
    "fox_model.wv.save_word2vec_format('fox_model.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def bais_genius(model):\n",
    "    man_diff = cosine(model['man'], model['genius'])\n",
    "    woman_diff = cosine(model['woman'], model['genius'])\n",
    "    return man_diff - woman_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.09093654155731201"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bais_genius(fox_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
